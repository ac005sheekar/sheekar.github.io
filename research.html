<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Research - Sheekar Banerjee</title>
  
  <meta name="author" content="Sheekar Banerjee">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
  <link rel="icon" type="image/png" href="sheekar2.jpg">
</head>

<body>
  <nav class="navbar navbar-expand-sm bg-dark navbar-dark">
    <!-- Brand/logo -->
    <a class="navbar-brand" href="index.html">Home</a>
    
    <!-- Links -->
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="research.html">Research</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="projects.html">Projects</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="teach.html">Teaching</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="leader.html">Leadership</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="workshops.html">Workshops</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="culture.html">Culture</a>
      </li>
    </ul>
  </nav><br>
  
        <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">

              <heading><strong>Research Interest</strong></heading><br><br>
              <a href="interest.PNG"><img style="width:30%;max-width:30%" alt="profile photo" src="interest.PNG" class="hoverZoomLink"></a>
            </td>
              <p style="text-align: center;">
                
                <!-- My research interests lie broadly in computer vision and artificial intelligence. My current focus majorly is to explore and conduct fundamental computer vision research with limited supervision, with a goal to conduct research and design products benefiting humanity. I am excited to be part of this fast-evolving and fascinating field, and I hope to contribute to its growth. -->
                <!-- and specifically in unsupervised learning and semi/self-supervised learning.  -->
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">

            <p>
              During my undergrad, I worked as an independent researcher at IUBAT CSE Robot-Vision Lab and 
              also as an undergraduate Research Assistant (RA) for multiple projects at the 
              <a href="https://iubat.edu/miyan-research-institute/">Miyan Research Institute</a>  
              under the supervision of 
              <a href="https://cse.iubat.edu/rashedul-islam/">Prof. Rashedul Islam</a>, 
              <a href="https://cse.iubat.edu/md-alomgir-hossain/">Prof. Md. Alomgir Hossain</a> and 
              <a href="https://cs.aiub.edu/profile/aminun.nahar">Prof. Aminun Nahar</a> (from 2017 to 2020).
            </p>
            <p>After my graduation, I was fortunate to get an opportunity to work as a Research Assistant 
              under the guidance of <a href="https://juniv.edu/teachers/ezharul.islam">Prof. Dr. Md. Ezharul Islam</a> 
              at <a href="https://juniv.edu/">Jahangirnagar University</a> 
              for a novel research project of Deep Learning based Computer Vision and Robotics in 2021 which led us winning the 
              <strong>
                <a href="https://drive.google.com/file/d/1Lx_0N-qDk464qy2mpFBdnzqiLk6QxPLf/view">Best Paper Award</a>
              </strong> 
              in the International Conference of MIDAS 2021, Springer.
            </p>
            <p>
              Later on, between 2021 to 2024, I worked as a Researcher and Deep Learning Algorithm Developer in  
              <a href="https://www.cisscom.com/">Cisscom</a> (United States),
              <a href="https://kaleidosoftgames.com/">KaleidoSoft</a> (Croatia) and 
              <a href="https://www.vinacts.com/">Vinacts</a> (South Korea).
    
              Currently, I am working as a Research Assistant (RA) 
              with <a href="https://www.linkedin.com/in/humayun-kabir-phd-49696515a/?originalSubdomain=kr">Prof. Dr. Humayun 
                Kabir</a>
              from the Department of Integrated System Engineering at <a href="https://eng.inha.ac.kr/eng/index.do">Inha 
                University</a>, South Korea. 
              My research field relates with
              developing state of the art efficient algorithms for Robot Vision capabilities 
              and medical image processing; occlusion aware object tracking and frame interpolation mechanism. 
              
              
            </p>
          </td>
        </tr>
      </tbody></table>


        





        <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <heading><strong>Publications</strong></heading><br><br>
              
            </td>
          </tr>
        </tbody></table>

        <!-- Papers list -->

        
          


          <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="breast.PNG" width="200" height="140">
            </td>
            <td width="75%" valign="middle">
              <a href= "https://link.springer.com/chapter/10.1007/978-3-031-53717-2_30">
                <papertitle>CEIMVEN: An Approach of Cutting Edge Implementation of Modified Versions of EfficientNet (V1-V2) Architecture for Breast Cancer Detection and Classification from Ultrasound Images</papertitle>
              </a>
              <br>
                <strong>Sheekar Banerjee</strong>, Md. Kamrul Hasan Monir<br>
              <em>Presented at the 2nd International Conference on Computing, IoT and Data Analytics (<strong> <a href="https://iccida.net/">ICCIDA</a></strong>)</em>, 2023.<br>
              <em>Published in the Studies in Computational Intelligence, Springer-Nature, Switzerland, 2024</em><br>
              [<a href="https://arxiv.org/abs/2308.13356">arXiv</a>]
              [<a href="https://docs.google.com/presentation/d/1TERuOyXkmCEQR01EPGFrGaff_N2szD9b/edit?usp=sharing&ouid=113883945430849884931&rtpof=true&sd=true">slides</a>] /
              [<a href="https://github.com/ac005sheekar/CEIMVEN">code</a>]
              <p> In this research, we focused mostly on our rigorous novel implementations and iterative result analysis of different cutting-edge modified versions of EfficientNet architectures namely EfficientNet-V1 (b0-b7) and EfficientNet-V2 (b0-b3) with ultrasound image, named as CEIMVEN. We utilized transfer learning approach here for using the pre-trained models of EfficientNet versions. The approximate testing accuracies we got from the modified versions of EfficientNet-V1 (b0- 99.15%, b1- 98.58%, b2- 98.43%, b3- 98.01%, b4- 98.86%, b5- 97.72%, b6- 97.72%, b7- 98.72%) and EfficientNet-V2 (b0- 99.29%, b1- 99.01%, b2- 98.72%, b3- 99.43%) are showing very bright future and strong potentials of deep learning approach for the successful detection and classification of breast cancers from the ultrasound images at a very early stage.</p>
              
            </td>
          </tr> </tbody></table>

<br><br>

          <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="combo_nano.png" width="200" height="140">
            </td>
            <td width="75%" valign="middle">
              <a href="https://link.springer.com/chapter/10.1007/978-981-19-2347-0_55">
                <papertitle>Nano Rover: A Multi-Sensory Full-Functional
                    Surveillance Robot with Modified Inception-Net</papertitle>
              </a>
              <br>
                <strong>Sheekar Banerjee</strong>, Aminun Nahar Jhumur, Md. Ezharul Islam<br>
              <em>Presented at the Machine Intelligence and Data Science Applications, 
                Proceedings of <strong><a href="https://link.springer.com/book/10.1007/978-981-19-2347-0">MIDAS 2021</a></strong></em>
              
              <em><strong>(<a href="https://drive.google.com/file/d/1Lx_0N-qDk464qy2mpFBdnzqiLk6QxPLf/view">Best Paper Award winner</a>)</strong></font>.</em><br>
              <em>Published in the Lecture Notes on Data Engineering and Communications Technologies, Springer-Nature, Singapore, 2022</em><br>
                
                [<a href="https://docs.google.com/presentation/d/1ASyFQ6cF2blp3uGTeCa4RvwnLy2elrsD/edit?usp=sharing&ouid=113883945430849884931&rtpof=true&sd=true">slides</a>]
                
              <p> Nano Rover is a significant approach of cost-efficient surveillance and reconnaissance robot which is fully functional and cost-efficient at the same time. It features the service of active reconnaissance mode with LIDAR sensor, location tracking with GPS Neo 6M module, visual information collection, person detection, weapons detection and identification, gender and age prediction of the hostile and other artificial threat detection, etc. Remote navigation plays as the core controlling system of the robot which is also modifiable through replacement with Internet and satellite navigation system. We modified the conventional Inception-Net architecture with a better hyper-parameter tuning for the successful execution of image processing tasks with a better level of accuracy so far.</p>
            </td>
          </tr> </tbody></table>

<br><br>


          <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="submarine.PNG" width="200" height="140">
            </td>
            <td width="75%" valign="middle">
              <a href="https://tis.wu.ac.th/index.php/tis/article/view/4205">
                <papertitle>A Novel Approach of Marine Ecosystem Monitoring System with Multi-Sensory Submarine on Robotic Platform for Visualizing the Climate Change Effect over Oceanic Environment</papertitle>
              </a>
              <br>
                <strong>Sheekar Banerjee</strong>, Aminun Nahar Jhumur<br>
              <em>International Journal- Trends in Sciences (<strong><a href="https://tis.wu.ac.th/index.php/tis/">TiS</a> </strong>)</em>, 2022 <br>
              
              <p> This robotics research project proposes a solution which appears to be a full-fledged Bluetooth controlled Submarine prototype with a sensory chipboard attached inside its endo-skeleton which contains multiple sensors like DHT11 temperature-humidity, dust, CO2 and YL69 pH sensors. The sensory data provides the information of underwater whether the naval environment is habitable for the marine biological species or not, under the terrible effect of global climate change. The submarine prototype is fully functional in the surface and underwater scenario which contains a very unique mechanical design and circuitry with an exceptional sensor data streaming capability which can be used by marine biological researchers and oceanographers professionally as a full-fledged marine ecosystem monitoring device.</p>
            </td>
          </tr> </tbody></table>

<br><br>

            <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="sim.jpg" width="200" height="140">
              </td>
              <td width="75%" valign="middle">
                <a href="https://www.researchgate.net/publication/379537385_The_Smart_Injector_A_Robotic_Approach_of_Automated_Multiple_Injection_System_for_Critical_Patients_using_Real_Time_Clock_Feature">
                  <papertitle>The Smart Injector: A Robotic Approach of
                    Automated Multiple Injection System for
                    Critical Patients using Real Time Clock Feature</papertitle>
                </a>
                <br>
                  <strong>Sheekar Banerjee</strong>, Md. Alomgir Hossain<br>
                  <em>Voluntary Research Work at IUBAT CSE Robotics Club</em>, 2019 <br>
                  [<a href="https://www.researchgate.net/publication/379537385_The_Smart_Injector_A_Robotic_Approach_of_Automated_Multiple_Injection_System_for_Critical_Patients_using_Real_Time_Clock_Feature#fullTextFileContent">ResearchGate</a>]
                  [<a href="https://github.com/ac005sheekar/Smart-Injector">code</a>]
                
                <p> In the rural world of medical services, we
                  generally notice a lot of havoc which generally happens
                  in the hospitals, clinics and related other medical
                  centers. The conditions of Intensive Care Units (ICU) of
                  the rural areas are quite intolerable because of the lack
                  of qualified nurses. Doctors generally prescribe multiple
                  injections for a single patient for each day. Nurses are
                  responsible for the injection process but unfortunately
                  they fail to perform the injection process very often in
                  proper prescribed time in proper amount. This
                  malpractice of treatment quite often results in the
                  terrible sufferings of the ICU patients and sometimes a
                  few patients even die. This study aims to minimize the
                  hazard at the highest accuracy level possible. The
                  research relates to the functionality of Real Time Clock
                  (RTC) which provides the activation of automated time
                  system and triggers the microcontroller's machinery to
                  act according to the time. According to the doctor's
                  prescribed time, injection's medicine will be flowing
                  inside the pipelines and will be injected to the body of
                  the patient through a cannula. In this study, Arduino
                  microcontroller, RTC DS3231 time module, HX 711
                  weight sensors, relay modules, hydraulic pump motors,
                  wifi shield, resistors, MOSFET and breadboard have
                  been used. Following the prescribed time of doctor, the
                  RTC module programs the time for the activation of the
                  microcontroller. The microcontroller activates the
                  hydraulic pump motors following the programmed
                  times. The pump motors then create a vacuum
                  environment inside the pipeline and pass the medicine
                  fluid for injection inside the patient's body through the
                  multiple channel-single cannula. This is consisted of
                  three units: electrical circuitry unit, mechanical unit
                  and timer program with reprogram process unit. The
                  research were carried out through the tests of each and
                  every units to verify that they were working precisely
                  and were manifesting the expected outputs.</p>
              </td>
              
            </tr> </tbody></table>

            

<br><br><br><br>
          
          


          


      
      </td>
    </tr>
  </table>
</body>

</html>
